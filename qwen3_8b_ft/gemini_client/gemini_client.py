#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç‹¬ç«‹çš„ Gemini LLM å®¢æˆ·ç«¯
ç”¨äºæ¨¡å‹è¯„ä¼°
"""

import argparse
import os
import time
import traceback
from pathlib import Path
from typing import Dict, List, Optional, Tuple

from google import genai
from google.api_core import exceptions as google_exceptions
from google.genai import types

current_dir = Path(__file__).resolve().parent

# Gemini é»˜è®¤é…ç½®
DEFAULT_GEMINI_CONFIG = {
    # LLMæä¾›å•†
    "provider": "gemini",
    # GeminiåŸºç¡€é…ç½®
    "project_id": "bigolive-ai-chat",  # GCPé¡¹ç›®ID
    "location": "us-central1",  # Gemini API åŒºåŸŸ
    "model": "gemini-2.5-pro",  # è¯„ä¼°ä½¿ç”¨çš„æ¨¡å‹
    "credentials_path": f"{current_dir}/gemini_config.json",  # GCPæœåŠ¡è´¦å·å¯†é’¥è·¯å¾„
    # è¶…æ—¶å’Œé‡è¯•é…ç½®
    "timeout": 300,  # è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    "max_retries": 3,  # å¤±è´¥é‡è¯•æ¬¡æ•°
    # ç”Ÿæˆå‚æ•°é…ç½®
    "temperature": 0.7,  # ç”Ÿæˆæ¸©åº¦
    "max_tokens": 4096,  # æœ€å¤§è¾“å‡ºtokenæ•°
    "thinking_budget": 128,  # æ€è€ƒé¢„ç®—
    # å®‰å…¨è®¾ç½®
    "safety_settings": [
        {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "OFF"},
        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "OFF"},
        {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "OFF"},
        {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "OFF"},
    ],
    # è®¡è´¹æ ‡ç­¾
    "billing_name": "peichao.murphy|saya-aichat-service",
    # è¯„ä¼°é…ç½®
    "batch_size": 4,  # è¯„ä¼°æ—¶çš„æ‰¹å¤„ç†å¤§å°
    "retry_delay": 5,  # é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
}


class GeminiClient:
    """Gemini è¯„ä¼°å®¢æˆ·ç«¯ï¼ˆç®€åŒ–ç‰ˆï¼Œç”¨äºæ¨¡å‹è¯„ä¼°ï¼‰"""

    def __init__(self, config: Optional[Dict] = None):
        """
        åˆå§‹åŒ– Gemini å®¢æˆ·ç«¯

        Args:
            config: Gemini é…ç½®å­—å…¸ï¼ˆå¯é€‰ï¼‰ã€‚å¦‚æœæä¾›ï¼Œä¼šè¦†ç›–é»˜è®¤é…ç½®
        """
        # åˆå¹¶é…ç½®ï¼šé»˜è®¤é…ç½® + ç”¨æˆ·é…ç½®
        self.config = DEFAULT_GEMINI_CONFIG.copy()
        if config:
            self.config.update(config)

        self._init_client()

    def _init_client(self):
        """åˆå§‹åŒ– Gemini å®¢æˆ·ç«¯"""
        print("=" * 70)
        print("ğŸ¤– Initializing Gemini Client")
        print("=" * 70 + "\n")

        try:
            # è¯»å–é…ç½®
            self.project_id = self.config["project_id"]
            self.location = self.config["location"]
            self.model_name = self.config["model"]
            self.temperature = self.config.get("temperature", 0.0)  # è¯„ä¼°æ—¶ä½¿ç”¨ä½æ¸©åº¦
            self.max_tokens = self.config.get("max_tokens", 4096)
            self.timeout = self.config.get("timeout", 60)

            print(f"  Project: {self.project_id}")
            print(f"  Location: {self.location}")
            print(f"  Model: {self.model_name}")
            print(f"  Temperature: {self.temperature}")
            print(f"  Max tokens: {self.max_tokens}")

            # è®¾ç½® Google åº”ç”¨å‡­æ®
            credentials_path = self.config.get("credentials_path")
            if credentials_path and os.path.exists(credentials_path):
                os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = credentials_path
                print(f"\n  âœ… Credentials loaded: {credentials_path}")
            else:
                print(f"\n  âš ï¸  Credentials not found: {credentials_path}")

            # åˆå§‹åŒ–å®¢æˆ·ç«¯
            self.client = genai.Client(
                vertexai=True,
                project=self.project_id,
                location=self.location,
            )

            print(f"\nâœ… Gemini client initialized successfully")
            print()

        except Exception as e:
            print(f"\nâŒ Failed to initialize Gemini client: {e}")
            traceback.print_exc()
            print()
            raise

    def _convert_messages_to_contents(self, messages: List[Dict]) -> Tuple[List, Optional[List]]:
        """
        è½¬æ¢æ ‡å‡†æ¶ˆæ¯æ ¼å¼ä¸º Gemini Content æ ¼å¼

        Args:
            messages: æ ‡å‡†æ¶ˆæ¯åˆ—è¡¨ [{"role": "user/system", "content": "..."}]

        Returns:
            (contents, system_instruction) å…ƒç»„
        """
        contents = []
        system_instruction = None

        for message in messages:
            role = message.get("role", "user")
            content = message.get("content", "")

            if role == "system":
                # ç³»ç»Ÿæ¶ˆæ¯ä½œä¸º system_instruction
                system_instruction = [types.Part.from_text(text=content)]
            elif role in ["user", "model", "assistant"]:
                # å°† assistant æ˜ å°„ä¸º model
                if role == "assistant":
                    role = "model"

                contents.append(types.Content(role=role, parts=[types.Part.from_text(text=content)]))

        return contents, system_instruction

    def generate(
        self,
        messages: List[Dict],
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        response_mime_type: Optional[str] = None,
    ) -> Tuple[str, int, str]:
        """
        ç”Ÿæˆå›å¤

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            temperature: æ¸©åº¦å‚æ•°ï¼ˆNone åˆ™ä½¿ç”¨é…ç½®ï¼‰
            max_tokens: æœ€å¤§è¾“å‡º token æ•°ï¼ˆNone åˆ™ä½¿ç”¨é…ç½®ï¼‰
            response_mime_type: å“åº”æ ¼å¼ï¼ˆå¦‚ "application/json"ï¼‰

        Returns:
            (response_text, total_tokens, finish_reason) å…ƒç»„
        """
        if not messages:
            return "", 0, "invalid_request"

        try:
            # è½¬æ¢æ¶ˆæ¯æ ¼å¼
            contents, system_instruction = self._convert_messages_to_contents(messages)

            # ä½¿ç”¨ä¼ å…¥å‚æ•°æˆ–é»˜è®¤é…ç½®
            request_temp = temperature if temperature is not None else self.temperature
            request_max_tokens = max_tokens if max_tokens is not None else self.max_tokens

            # é…ç½®ç”Ÿæˆå‚æ•°
            config_params = {
                "temperature": request_temp,
                "max_output_tokens": request_max_tokens,
            }

            # å¦‚æœæŒ‡å®šäº†å“åº”æ ¼å¼
            if response_mime_type:
                config_params["response_mime_type"] = response_mime_type

            generate_content_config = types.GenerateContentConfig(**config_params)

            # æ·»åŠ ç³»ç»ŸæŒ‡ä»¤
            if system_instruction:
                generate_content_config.system_instruction = system_instruction

            start_time = time.time()

            # è°ƒç”¨ API
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=contents,
                config=generate_content_config,
            )
            # print(f"[DEBUG] gemini response: {response}")

            # å¤„ç†å“åº”
            end_time = time.time()
            response_time = end_time - start_time

            # ç»Ÿè®¡ token ä½¿ç”¨
            usage = response.usage_metadata
            input_tokens = getattr(usage, "prompt_token_count", 0) or 0
            output_tokens = getattr(usage, "candidates_token_count", 0) or 0
            total_tokens = input_tokens + output_tokens

            if response and response.text:
                return response.text, total_tokens, "stop"
            else:
                return "", 0, "empty_response"

        except google_exceptions.DeadlineExceeded:
            print("gemini error: deadline exceeded")
            return "", 0, "timeout"

        except google_exceptions.PermissionDenied as e:
            print("gemini error: permission denied")
            return "", 0, "permission_denied"

        except google_exceptions.InvalidArgument as e:
            print("gemini error: invalid argument")
            return "", 0, "invalid_argument"

        except google_exceptions.ResourceExhausted as e:
            print("gemini error: resource exhausted")
            return "", 0, "resource_exhausted"

        except Exception as e:
            print(f"gemini error: {e}")
            return "", 0, "error"


if __name__ == "__main__":
    """æµ‹è¯• Gemini å®¢æˆ·ç«¯"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="æµ‹è¯• Gemini å®¢æˆ·ç«¯")
    parser.add_argument("--model", type=str, help="æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼Œè¦†ç›–é»˜è®¤é…ç½®ï¼‰")
    parser.add_argument("--temperature", type=float, help="æ¸©åº¦å‚æ•°ï¼ˆå¯é€‰ï¼Œè¦†ç›–é»˜è®¤é…ç½®ï¼‰")
    parser.add_argument("--credentials", type=str, help="å‡­è¯æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œè¦†ç›–é»˜è®¤é…ç½®ï¼‰")
    args = parser.parse_args()

    # æ„å»ºè‡ªå®šä¹‰é…ç½®ï¼ˆè¦†ç›–é»˜è®¤å€¼ï¼‰
    custom_config = {}
    if args.model:
        custom_config["model"] = args.model
    if args.temperature is not None:
        custom_config["temperature"] = args.temperature
    if args.credentials:
        custom_config["credentials_path"] = args.credentials

    print("\n" + "=" * 70)
    print("ğŸ§ª Testing Gemini Client")
    print("=" * 70 + "\n")

    print("  Configuration:")
    print(f"    Using default config + custom overrides")
    if custom_config:
        print(f"    Custom config: {custom_config}")
    print()

    # åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼ˆä½¿ç”¨é»˜è®¤é…ç½® + è‡ªå®šä¹‰è¦†ç›–ï¼‰
    client = GeminiClient(config=custom_config if custom_config else None)

    # æµ‹è¯•è°ƒç”¨
    print("=" * 70)
    print("ğŸš€ Testing API Call")
    print("=" * 70 + "\n")

    # messages = [{"role": "user", "content": 'Hello! Please respond with a JSON: {"greeting": "your greeting here"}'}]
    import json
    from pprint import pprint

    with open("qwen3_8b_ft/recom_reply_format_sft/data/recom_reply_turn_ge6_2025-11-25/train.jsonl", "r") as f:
        for line in f.readlines():
            data = json.loads(line)
            pprint(data)
            messages = [data["messages"][0]]
            break

    print("-" * 60)
    pprint(messages)
    response, tokens, finish_reason = client.generate(messages=messages, response_mime_type="application/json")

    print("\n" + "=" * 70)
    print("ğŸ“Š Test Results")
    print("=" * 70 + "\n")
    print(f"  Response: {response}")
    print(f"  Tokens: {tokens}")
    print(f"  Finish reason: {finish_reason}")
    print(f"\nâœ… Test completed")
    print()
